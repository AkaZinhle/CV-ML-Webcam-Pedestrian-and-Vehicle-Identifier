{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfTzZwiHlx4o",
        "outputId": "7e2b5e09-723e-48aa-e408-9712ec6330e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.49)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "# YOLOv5 and PyTorch for object detection\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# OpenCV for image processing and real-time video capture\n",
        "import cv2\n",
        "\n",
        "# TensorFlow for potential neural network integration\n",
        "import tensorflow as tf\n",
        "\n",
        "# NumPy for numerical operations\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib for plotting and visualizing data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pandas for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Pathlib for file path operations\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# JSON for handling JSON data\n",
        "import json\n",
        "\n",
        "# TensorFlow Keras for image preprocessing\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Scikit-learn for class weight computation and data splitting\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TensorFlow Keras callbacks for early stopping during training\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# TQDM for progress bars\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Shutil for file operations\n",
        "import shutil\n",
        "\n",
        "# Pillow (PIL) for image processing\n",
        "from PIL import Image\n",
        "\n",
        "# Kaggle API for dataset handling and competition submissions\n",
        "import kagglehub\n",
        "\n",
        "#Displaying Results\n",
        "import random\n",
        "import os\n",
        "\n",
        "#Imports for live camera and real-time detection\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2crJOhPcClI",
        "outputId": "ba640afa-728b-4f2c-89ff-b5d1f476cd93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/klemenko/kitti-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 12.0G/22.5G [09:24<08:17, 22.7MB/s]\n"
          ]
        },
        {
          "ename": "ChunkedEncodingError",
          "evalue": "('Connection broken: IncompleteRead(12836669426 bytes read, 11304182579 more expected)', IncompleteRead(12836669426 bytes read, 11304182579 more expected))",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m                 \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0;31m# Content-Length are caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_bytes_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength_remaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m             elif read1 and (\n",
            "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(12836669426 bytes read, 11304182579 more expected)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    976\u001b[0m                 \u001b[0;31m# it one byte at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m                 \u001b[0mdecoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Connection broken: {e!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(12836669426 bytes read, 11304182579 more expected)', IncompleteRead(12836669426 bytes read, 11304182579 more expected))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9a9ab913786c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download latest version of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"klemenko/kitti-dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path to dataset files:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/datasets.py\u001b[0m in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dataset_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Dataset: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# First, we download the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;31m# Create the directory to extract the archive to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading from {url}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0m_download_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36m_download_file\u001b[0;34m(response, out_file, size_read, total_size, hash_object)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_divisor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mContentDecodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(12836669426 bytes read, 11304182579 more expected)', IncompleteRead(12836669426 bytes read, 11304182579 more expected))"
          ]
        }
      ],
      "source": [
        "# Download latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"klemenko/kitti-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LvcnW9nRcPbf"
      },
      "outputs": [],
      "source": [
        "# Specify the base directory for the KITTI dataset\n",
        "base_dir = Path('/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1')\n",
        "\n",
        "# Define the path to the directory containing the training images\n",
        "data_path = base_dir / 'data_object_image_2' / 'training' / 'image_2'\n",
        "\n",
        "# Define the path to the directory containing the training images\n",
        "test_path = base_dir / 'data_object_image_2' / 'testing' / 'image_2'\n",
        "\n",
        "# Define the path to the directory containing the corresponding labels for the training images\n",
        "label_path = base_dir / 'data_object_label_2' / 'training' / 'label_2'\n",
        "\n",
        "# Define a dictionary mapping class names to integer labels\n",
        "classes = {\n",
        "    'Car': 0,              # Label for Car\n",
        "    'Pedestrian': 1,       # Label for Pedestrian\n",
        "    'Van': 2,              # Label for Van\n",
        "    'Cyclist': 3,          # Label for Cyclist\n",
        "    'Truck': 4,            # Label for Truck\n",
        "    'Misc': 5,             # Label for miscellaneous objects\n",
        "    'Tram': 6,             # Label for Tram\n",
        "    'Person_sitting': 7    # Label for a person sitting\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eh-_drQxc1Dx"
      },
      "outputs": [],
      "source": [
        "# Generate a sorted list of all files in the training images directory\n",
        "# This will include all image files located in 'data_path'\n",
        "data = sorted(list(data_path.glob('*')))\n",
        "\n",
        "# Generate a sorted list of all files in the labels directory\n",
        "# This will include all label files located in 'label_path'\n",
        "labels = sorted(list(label_path.glob('*')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xS8pSi_clbMs"
      },
      "outputs": [],
      "source": [
        "# Combine the sorted lists of images and labels into pairs\n",
        "# Each pair will contain a corresponding image file and its label file\n",
        "pairs = list(zip(data, labels))\n",
        "\n",
        "# Display the first two pairs to verify the zipping process\n",
        "pairs[:2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8Rnk_iktc9_Y"
      },
      "outputs": [],
      "source": [
        "# Split the pairs of images and labels into training and testing sets\n",
        "# `test_size=0.2` specifies that 20% of the pairs will be used for testing\n",
        "# `shuffle=True` ensures that the pairs are shuffled before splitting\n",
        "train, test = train_test_split(pairs, test_size=0.2, shuffle=True)\n",
        "\n",
        "# Print the number of pairs in the training and testing sets to verify the split\n",
        "len(train), len(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "puMzdce7c__0"
      },
      "outputs": [],
      "source": [
        "# Define the path for the training split directory and resolve it to an absolute path\n",
        "train_split_path = Path('train').resolve()\n",
        "\n",
        "# Create the training split directory if it does not already exist\n",
        "train_split_path.mkdir(exist_ok=True)\n",
        "\n",
        "# Define the path for the validation split directory and resolve it to an absolute path\n",
        "valid_path = Path('valid').resolve()\n",
        "\n",
        "# Create the validation split directory if it does not already exist\n",
        "valid_path.mkdir(exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K1BBAR1nkGFv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_kitti_to_yolo(label_file, img_width, img_height):\n",
        "    \"\"\"Converts KITTI label format to YOLO format.\"\"\"\n",
        "\n",
        "    # Open the label file and read all lines\n",
        "    with open(label_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Initialize an empty list to store YOLO annotations\n",
        "    yolo_annotations = []\n",
        "\n",
        "    # Process each line in the label file\n",
        "    for line in lines:\n",
        "        # Split the line into individual data components\n",
        "        data = line.strip().split(' ')\n",
        "        class_name = data[0]\n",
        "\n",
        "        # Check if the class name is in the predefined classes\n",
        "        if class_name in classes:\n",
        "            class_id = classes[class_name]  # Get the class ID\n",
        "            x_min = float(data[4])  # Minimum x-coordinate of the bounding box\n",
        "            y_min = float(data[5])  # Minimum y-coordinate of the bounding box\n",
        "            x_max = float(data[6])  # Maximum x-coordinate of the bounding box\n",
        "            y_max = float(data[7])  # Maximum y-coordinate of the bounding box\n",
        "\n",
        "            # Normalize coordinates to [0, 1]\n",
        "            x_center = ((x_min + x_max) / 2) / img_width  # X center of the bounding box\n",
        "            y_center = ((y_min + y_max) / 2) / img_height  # Y center of the bounding box\n",
        "            width = (x_max - x_min) / img_width  # Width of the bounding box\n",
        "            height = (y_max - y_min) / img_height  # Height of the bounding box\n",
        "\n",
        "            # Append the YOLO formatted annotation to the list\n",
        "            yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "    # Return the list of YOLO annotations\n",
        "    return yolo_annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q-VdJQTOdBr_"
      },
      "outputs": [],
      "source": [
        "# Loop through each pair of training images and labels\n",
        "for t_img, t_lb in tqdm(train):\n",
        "    # Define the path for copying the image to the training split directory\n",
        "    im_path = train_split_path / t_img.name\n",
        "\n",
        "    # Define the path for copying the label to the training split directory\n",
        "    lb_path = train_split_path / t_lb.name\n",
        "\n",
        "    # Copy the training image to the designated path\n",
        "    shutil.copy(t_img, im_path)\n",
        "\n",
        "    # Copy the training label to the designated path\n",
        "    shutil.copy(t_lb, lb_path)\n",
        "\n",
        "    # Open the copied image to get its dimensions\n",
        "    img = Image.open(im_path)\n",
        "    img_width, img_height = img.size\n",
        "\n",
        "    # Convert the KITTI format label to YOLO format\n",
        "    yolo_annotations = convert_kitti_to_yolo(t_lb, img_width, img_height)\n",
        "\n",
        "    # Save the YOLO formatted annotations to the corresponding label file\n",
        "    with open(lb_path, 'w') as f:\n",
        "        f.write('\\n'.join(yolo_annotations))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ucQU11_LdDkY"
      },
      "outputs": [],
      "source": [
        "# Loop through each pair of testing images and labels\n",
        "for t_img, t_lb in tqdm(test):\n",
        "    # Define the path for copying the image to the validation split directory\n",
        "    im_path = valid_path / t_img.name\n",
        "\n",
        "    # Define the path for copying the label to the validation split directory\n",
        "    lb_path = valid_path / t_lb.name\n",
        "\n",
        "    # Copy the testing image to the designated path\n",
        "    shutil.copy(t_img, im_path)\n",
        "\n",
        "    # Copy the testing label to the designated path\n",
        "    shutil.copy(t_lb, lb_path)\n",
        "\n",
        "    # Open the copied image to get its dimensions\n",
        "    img = Image.open(im_path)\n",
        "    img_width, img_height = img.size\n",
        "\n",
        "    # Convert the KITTI format label to YOLO format\n",
        "    yolo_annotations = convert_kitti_to_yolo(t_lb, img_width, img_height)\n",
        "\n",
        "    # Save the YOLO formatted annotations to the corresponding label file\n",
        "    with open(lb_path, 'w') as f:\n",
        "        f.write('\\n'.join(yolo_annotations))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F5jH1o82d3BC"
      },
      "outputs": [],
      "source": [
        "# Initialize a string for the YAML file content\n",
        "# 'names:' indicates the start of the class names section\n",
        "yaml_file = 'names:\\n'\n",
        "\n",
        "# Add each class name to the YAML file content, with a preceding hyphen and space\n",
        "yaml_file += '\\n'.join(f'- {c}' for c in classes)\n",
        "\n",
        "# Add the number of classes ('nc') to the YAML file content\n",
        "yaml_file += f'\\nnc: {len(classes)}'\n",
        "\n",
        "# Add the paths for the training and validation data to the YAML file content\n",
        "yaml_file += f'\\ntrain: {str(train_split_path)}\\nval: {str(valid_path)}'\n",
        "\n",
        "# Write the YAML file content to 'data.yaml'\n",
        "with open('data.yaml', 'w') as f:\n",
        "    f.write(yaml_file)\n",
        "\n",
        "# Display the content of 'data.yaml' to verify its correctness\n",
        "!cat data.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9cAb0N6Zcgtx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import pathlib # Importing the pathlib module\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "def load_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name,\n",
        "    origin=base_url + model_file,\n",
        "    untar=True)\n",
        "\n",
        "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "  model = tf.saved_model.load(str(model_dir))\n",
        "  model = model.signatures['serving_default']\n",
        "\n",
        "  return model\n",
        "\n",
        "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "model = load_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h7pT_Ds3P7M5"
      },
      "outputs": [],
      "source": [
        "# Define early stopping criterion to prevent overfitting\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='accuracy',  # Monitor the 'accuracy' metric to decide when to stop training\n",
        "    min_delta=0.01,  # Minimum change in the monitored metric to qualify as an improvement (0.01 means 1% improvement)\n",
        "    patience=3,  # Number of epochs with no improvement after which training will be stopped (wait for 2 epochs with no improvement)\n",
        "    restore_best_weights=True,  # Restore the model weights from the epoch with the best accuracy once training stops\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JmUWMQW0ejSa"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Specify the use of a specific GPU device for training (e.g., GPU:1)\n",
        "with tf.device('/GPU:1'):\n",
        "    # Set the number of training epochs\n",
        "    epochs = 1\n",
        "\n",
        "    # Train the YOLOv8 model with the specified parameters\n",
        "    train_results = model.train(\n",
        "        data='data.yaml',       # Path to the data configuration file\n",
        "        epochs=epochs,          # Number of training epochs\n",
        "        patience=3,             # Early stopping patience; stop training if no improvement after 3 epochs\n",
        "        mixup=0.5,              # Mixup augmentation rate\n",
        "        project='yolov8_Assignment',  # Name of the project for saving results\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HOnMBDmXerlq"
      },
      "outputs": [],
      "source": [
        "# Validate the trained YOLOv8 model using the specified data configuration file\n",
        "valid_results = model.val(data='data.yaml')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cFN0gm_ePxC-"
      },
      "outputs": [],
      "source": [
        "# Get all metrics as a dictionary for comprehensive evaluation\n",
        "all_metrics = valid_results.results_dict\n",
        "\n",
        "# Print all metrics with descriptive labels\n",
        "print(\"\\nAll Metrics:\")\n",
        "for key, value in all_metrics.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E3owveglmGAu"
      },
      "outputs": [],
      "source": [
        "# Create a new figure with a specified size\n",
        "plt.figure(figsize=(10, 20))\n",
        "\n",
        "# Open and display the image of training results from the specified path\n",
        "plt.imshow(Image.open('yolov8_Assignment/train/results.png'))\n",
        "\n",
        "# Remove the axis for better visualization of the image\n",
        "plt.axis('off')\n",
        "\n",
        "# Display the image\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Ictd6zqmQJ2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,20))\n",
        "plt.imshow(Image.open('yolov8_Assignment/train2/confusion_matrix.png'))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TgJbYB0Nuv7f"
      },
      "outputs": [],
      "source": [
        "colors = {\n",
        "    'Car': (255, 0, 0),          # Red\n",
        "    'Pedestrian': (0, 255, 0),   # Green\n",
        "    'Van': (0, 0, 255),          # Blue\n",
        "    'Cyclist': (255, 255, 0),    # Cyan\n",
        "    'Truck': (255, 0, 255),      # Magenta\n",
        "    'Misc': (0, 255, 255),       # Yellow\n",
        "    'Tram': (128, 0, 128),       # Purple\n",
        "    'Person_sitting': (0, 128, 0) # Dark Green\n",
        "}\n",
        "\n",
        "image_files = os.listdir(test_path)\n",
        "\n",
        "# Randomly select 10 images (or fewer if there are not enough)\n",
        "num_images_to_show = 10\n",
        "image_paths = random.sample([os.path.join(test_path, img) for img in image_files], min(num_images_to_show, len(image_files)))\n",
        "\n",
        "processed_images = []\n",
        "\n",
        "# Get the list of class names from the 'classes' dictionary\n",
        "class_names = list(classes.keys())\n",
        "# Continue with the loop as before\n",
        "for image_path in image_paths:\n",
        "    # Run inference on the image\n",
        "    results = model.predict(image_path)\n",
        "\n",
        "    # Read the image once\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
        "\n",
        "    # Accessing the predictions\n",
        "    for result in results:\n",
        "        boxes = result.boxes  # Bounding boxes\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0]  # Top-left and bottom-right corners\n",
        "            confidence = box.conf[0]      # Confidence score\n",
        "            class_id = int(box.cls[0])    # Class ID\n",
        "\n",
        "            # Get the class name from the class ID\n",
        "            class_name = class_names[class_id] if class_id < len(class_names) else \"Unknown\"\n",
        "\n",
        "            # Print the class name and confidence value for all classes\n",
        "            print(f\"Class Name: {class_name}, Class ID: {class_id}, Confidence: {confidence}, BBox: [{x1}, {y1}, {x2}, {y2}]\")\n",
        "\n",
        "            # Create the label text with class name and confidence\n",
        "            label_text = f\"{class_name} ({confidence:.2f})\"\n",
        "\n",
        "            # Get the color for the current class\n",
        "            color = colors.get(class_name, (255, 255, 255))  # Default to white if class not found\n",
        "\n",
        "            # Draw the bounding box on the image with the specified color\n",
        "            cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
        "\n",
        "            # Add label text on top of the bounding box\n",
        "            cv2.putText(img, label_text, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "    # Append the processed image to the list\n",
        "    processed_images.append(img)\n",
        "\n",
        "    # Display the processed images in a grid\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i, processed_img in enumerate(processed_images):\n",
        "    plt.subplot(4, 3, i + 1)  # Adjust the grid size as needed\n",
        "    plt.imshow(processed_img)\n",
        "    plt.axis('off')  # Hide axis\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QU71SSvlth2X"
      },
      "outputs": [],
      "source": [
        "# Function to capture a single frame from the webcam\n",
        "def capture_frame(quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function captureFrame(quality) {\n",
        "            const video = document.createElement('video');\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            // Create video element and start stream\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Capture a single frame to a canvas\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "            // Stop the stream and return the image data\n",
        "            stream.getTracks().forEach(track => track.stop());\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js(f'captureFrame({quality})')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    img_array = np.frombuffer(binary, np.uint8)\n",
        "    return cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Function to perform object detection on a single frame\n",
        "def detect_objects_on_frame(frame, model, labels):\n",
        "    # Perform inference using the YOLOv8 model\n",
        "    results = model(frame)\n",
        "\n",
        "    # Get detections and class names\n",
        "    detections = results[0].boxes.data.cpu().numpy()\n",
        "    class_ids = detections[:, -1].astype(int)\n",
        "\n",
        "    for detection in detections:\n",
        "        x1, y1, x2, y2, confidence, class_id = detection\n",
        "\n",
        "        # Filter weak detections (adjust threshold as needed)\n",
        "        if confidence > 0.3:\n",
        "\n",
        "            # Draw bounding box and label\n",
        "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "            label = f\"{list(labels.keys())[list(labels.values()).index(class_id)]}: {confidence * 100:.2f}%\"  # Get label from class_id\n",
        "            cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Main function to run detection in Colab\n",
        "def run_object_detection_colab(model, labels):\n",
        "    print(\"Press 'Stop' in Colab to exit the loop.\")\n",
        "    try:\n",
        "        while True:\n",
        "            # Capture a frame\n",
        "            frame = capture_frame()\n",
        "            if frame is None:\n",
        "                print(\"No frame captured.\")\n",
        "                break\n",
        "\n",
        "            # Perform object detection\n",
        "            processed_frame = detect_objects_on_frame(frame, model, labels)\n",
        "\n",
        "            # Display the processed frame\n",
        "            cv2_imshow(processed_frame)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Detection stopped.\")\n",
        "\n",
        "# Run the object detection\n",
        "run_object_detection_colab(model, classes)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}